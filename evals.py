# -*- coding: utf-8 -*-
"""AliceZhangEvals-Algoverse.ipynb

Automatically generated by Colab.
"""

# !pip install "openai>=1.0.0" "datasets>=2.0.0"
# !pip install datasets

"""# 1. Retrieving Data"""

from datasets import load_dataset
dataset = load_dataset("allenai/ai2_arc", 'ARC-Challenge')

# train test val dimensions
print(dataset)

# taking a look at the data
print(dataset["train"][0])
print(dataset["validation"][0])
print(dataset["test"][0])
dataset["train"].features

import pandas as pd
# df are elite
df = pd.DataFrame(dataset["train"])
df.head()

"""#2. Accuracy Measurement"""

val = dataset['validation']
print(val)

def format_prompt(example):
  question = example['question']
  choices = example['choices']
  answer = example['answerKey']

  lines = [question]
  for i in range(len(choices['text'])):
    label = choices['label'][i]
    text = choices['text'][i]
    lines.append(f"{label}. {text}")
  return '\n'.join(lines)

prompts = [format_prompt(ex) for ex in val]

# sanity check
print(prompts[202])

# from google.colab import userdata
# key = userdata.get(OPENAI_API_KEY)
import os
# MODEL_ID = userdata.get("MODEL_ID")
# os.environ["OPENAI_API_KEY"] = key

from openai import OpenAI
client = OpenAI()
def call_model(prompt: str):
  response = client.responses.create(
      model = MODEL_ID,
      temperature = 0, # deterministic
      input = [
          {
              "role": "user",
              "content": prompt
          }
      ],
      include=["message.output_text.logprobs"]
  )
  content = response.output[0].content[0]
  # prediction = content.text.strip()
  prediction = next((c for c in content.text if c.isupper()), None) # trying to avoid issues with whitespace/non-answer output
  logprob = content.logprobs[0].logprob
  return prediction, logprob

prediction, logprob = call_model(prompts[0])
print(prediction, logprob)

import math
val_df = pd.DataFrame(val)
predictions = []
accurate = []
confidence = []

for i, prompt in enumerate(prompts):
  pred, lp = call_model(prompt)
  predictions.append(pred)
  accurate.append(pred == val_df['answerKey'][i])
  confidence.append(math.exp(lp))

print(predictions)

val_df['predictions'] = predictions
val_df['o'] = accurate
val_df['confidence'] = confidence
accuracy = val_df['o'].mean()
print(f"{accuracy*100:.1f}%")
print(f"{accuracy:.8f}%")
# this was really slow ~3mins

"""#3. Calibration Analysis using Brier Score"""

brier = ((val_df["confidence"] - val_df["o"]) ** 2).mean()
print(f"Brier score: {brier:.4f}")

"""#4. Error Footprint"""

threshold = 0.99
val_df["answered?"] = val_df["confidence"] >= threshold
answered_df = val_df[val_df["answered?"]]

selective_accuracy = (answered_df["o"].sum() / len(answered_df)) if len(answered_df) > 0 else 0
print(f"Selective Accuracy: {selective_accuracy*100:.1f}%")
coverage = val_df["answered?"].mean()
print(f"Coverage: {coverage*100:.1f}%")

